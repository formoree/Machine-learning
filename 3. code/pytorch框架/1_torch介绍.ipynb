{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1d5234e",
   "metadata": {},
   "source": [
    "# pytorch与tensorflow的区别 \n",
    "+ torch: 简单和灵活\n",
    "+ 张量：可以在GPU或其他专用硬件上运行，加速效果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e7bf19",
   "metadata": {},
   "source": [
    "# 利用torch解决线性回归问题 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294ee36c",
   "metadata": {},
   "source": [
    "## 完整代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "005419d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 148.56253051757812\n",
      "epoch: 50 loss: 1.5162343978881836\n",
      "epoch: 100 loss: 0.9879584312438965\n",
      "epoch: 150 loss: 0.6436681747436523\n",
      "epoch: 200 loss: 0.4193764626979828\n",
      "epoch: 250 loss: 0.2732224464416504\n",
      "epoch: 300 loss: 0.1780959814786911\n",
      "epoch: 350 loss: 0.1160411462187767\n",
      "epoch: 400 loss: 0.07564301788806915\n",
      "epoch: 450 loss: 0.04923228919506073\n",
      "epoch: 500 loss: 0.03211582452058792\n",
      "epoch: 550 loss: 0.020908044651150703\n",
      "epoch: 600 loss: 0.013639013282954693\n",
      "epoch: 650 loss: 0.00891256332397461\n",
      "epoch: 700 loss: 0.005786513909697533\n",
      "epoch: 750 loss: 0.003886700375005603\n",
      "epoch: 800 loss: 0.0024582520127296448\n",
      "epoch: 850 loss: 0.0016097445040941238\n",
      "epoch: 900 loss: 0.0010669843759387732\n",
      "epoch: 950 loss: 0.00077777449041605\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#torch里要求的数据类型必须是float\n",
    "#函数返回一个有终点和起点的固定步长的排列\n",
    "x = np.arange(1,12,dtype = np.float32).reshape(-1,1)\n",
    "y = 2 * x + 3\n",
    "\n",
    "##重新定义线性回归 继承nn.module，实现前向传播\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super().__init__()#继承父类的方法\n",
    "        self.linear = nn.Linear(input_dim,output_dim) #定义全连接层\n",
    "        \n",
    "    def forward(self,inp):\n",
    "        out = self.linear(inp) \n",
    "        return out\n",
    "    \n",
    "regression_model = LinearRegressionModel(1,1)\n",
    "\n",
    "#指定模型的训练方式 CPU or GPU  注意是cuda不是cude\n",
    "device = torch.device(\"cuda:0\"if torch.cuda.is_available() else \"cpu\")\n",
    "regression_model.to(device)\n",
    "\n",
    "#设置参数\n",
    "epochs = 1000  # 训练次数\n",
    "learning_rate = 0.01  # 学习速率\n",
    "optimizer = torch.optim.SGD(regression_model.parameters(), learning_rate)  # 优化器（未来会详细介绍），这里使用随机梯度下降算法（SGD）\n",
    "criterion = nn.MSELoss()  # 使用均方误差定义损失函数\n",
    "\n",
    "#进行训练\n",
    "for epoch in range(epochs):\n",
    "    #数据类型的转换\n",
    "    inputs = torch.from_numpy(x).to(device)\n",
    "    labels = torch.from_numpy(y).to(device)\n",
    "    \n",
    "    #训练\n",
    "    optimizer.zero_grad() #每次求偏导都会清零，否则会进行叠加\n",
    "    outputs = regression_model(inputs)\n",
    "    loss = criterion(outputs,labels) #通过均方误差评估预测误差\n",
    "    loss.backward() #反向传播\n",
    "    optimizer.step() #更新权重参数\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print(\"epoch:\",epoch,\"loss:\",loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e039f5",
   "metadata": {},
   "source": [
    "## 函数详细讲解 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6534521c",
   "metadata": {},
   "source": [
    "### reshape \n",
    "+ numpy.arange(n).reshape(a, b) 依次生成n个自然数，并且以a行b列的数组形式显示\n",
    "+ mat (or array).reshape(c, -1) 必须是矩阵格式或者数组格式，才能使用 .reshape(c, -1) 函数\n",
    "    + 1的作用就在此: **自动计算d：d=数组或者矩阵里面所有的元素个数/c**, d必须是整数，不然报错\n",
    "+ 常见用法：\n",
    "    + reshape(1,-1)转化成1行\n",
    "    + reshape(2,-1)转换成两行\n",
    "    + reshape(-1,1)转换成1列："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ff69d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 4.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [ 7.],\n",
       "       [ 8.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [11.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(1,12,dtype = np.float32)\n",
    "x.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f74f3e7",
   "metadata": {},
   "source": [
    "### torch.device() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582f9d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#这行代码的意思是将所有最开始读取数据时的tensor变量copy一份到device所指定的GPU上去，\n",
    "# 之后的运算都在GPU上进行。\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "##多个GPU的使用方法\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Model()\n",
    "if torch.cuda.device_count() > 1:#device_count计算GPU个数\n",
    "    model = nn.DataParallel(model，device_ids=[0,1,2])\n",
    "model.to(device）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3732ffc",
   "metadata": {},
   "source": [
    "### Tensor总结\n",
    "+ Tensor 和 Numpy都是矩阵，区别是前者可以在GPU上运行，后者只能在CPU上；\n",
    "+ Tensor和Numpy互相转化很方便，类型也比较兼容\n",
    "+ Tensor可以直接通过print显示数据类型，而Numpy不可以"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python38]",
   "language": "python",
   "name": "conda-env-python38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
