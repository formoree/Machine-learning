{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简单介绍 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**我们把对训练集中的一个 Batch 运算更新一次叫做一个 Step，对训练集的所有样本循环迭代一次叫做一个 Epoch**\n",
    "+ epochs：训练分为几个时期。每一个epoch是对整个输入数据的一次迭代（此操作以较小的批次完成）。\n",
    "+ batch_size：当传递NumPy数据时，模型将数据切成较小的批次，并在训练期间对这些批次进行迭代。该整数指定每个批次的大小。请注意，如果不能将样本总数除以批次大小，则最后一批可能会更小。\n",
    "+ validation_data：在模型训练时，监控在某些验证数据上监视其性能。传递此参数（输入和标签的元组）可以使模型在每个时期结束时以推断模式显示所传递数据的损失和度量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([1.])\n",
    "w = tf.constant([2.])\n",
    "# #括号中选择永久保存\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    #注意 [w] 中的w必须放在tape.watch()中.因为这个w不是tf.Variable型\n",
    "    tape.watch([w])\n",
    "    y1 = x + w\n",
    "grad = tape.gradient(y1,[w])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'dtype'\n"
     ]
    }
   ],
   "source": [
    "    # 2nd-gradient\n",
    "    b = tf.constant([3.])\n",
    "    \n",
    "try:\n",
    "        with tf.GradientTape() as t1:\n",
    "            with tf.GradientTape() as t2:\n",
    "                y = x + w + b\n",
    "            y_x = t2.gradient(y,[b])\n",
    "        y_x2 = t1.gradient(y_x,[b])\n",
    "        y_x2\n",
    "        # y_w2 = t1.gradient(y_w,w)\n",
    "except Exception as e :\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 激活函数及其梯度\n",
    "+ tf.sigmoid():x较大会出现偏导为0的情况(梯度消失)\n",
    "+ tf.tanh()\n",
    "+ tf.nn.relu() 减少梯度爆炸或者梯度下降的操作\n",
    "   + tf.nn.relu6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 损失函数及其梯度\n",
    "+ tf.reduce_mean(tf.losses.MSE(y,out)) \n",
    "+ tf.losses.categorical_crossentropy(y,out):softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 单输出感知机及其梯度 \n",
    "+ MSE中的参数y_pred必须是tf.float32型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=244, shape=(3, 1), dtype=float32, numpy=\n",
       "array([[-0.01808497],\n",
       "       [ 0.01421455],\n",
       "       [-0.0117125 ]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal([1,3])\n",
    "b = tf.ones([1])\n",
    "w = tf.ones([3,1])\n",
    "y = tf.constant([1])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch([w,b])\n",
    "    prob = tf.sigmoid(x @ w + b)    \n",
    "    loss = tf.reduce_mean(tf.losses.MSE(prob,y))\n",
    " \n",
    "grads = tape.gradient(loss,[w,b])\n",
    "grads[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多输出感知机及其梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=304, shape=(4, 3), dtype=float32, numpy=\n",
       "array([[ 0.08003316, -0.04320253, -0.03683063],\n",
       "       [ 0.11648539, -0.02440556, -0.09207983],\n",
       "       [ 0.1069216 , -0.11589715,  0.00897555],\n",
       "       [ 0.11371143,  0.04293453, -0.15664595]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal([2,4])\n",
    "b = tf.ones([3])\n",
    "w = tf.ones([4,3])\n",
    "y = tf.constant([2,0])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch([w,b])\n",
    "    #axis=1 表示结果[b,3]中的3这个维度为概率\n",
    "    prob = tf.nn.softmax(x @ w + b,axis=1)    \n",
    "    loss = tf.reduce_mean(tf.losses.MSE(tf.one_hot(y,depth=3),prob))\n",
    " \n",
    "grads = tape.gradient(loss,[w,b])\n",
    "grads[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 手写数字识别实战\n",
    "见py文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBorad可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  优化一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4600/2815275330.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0my_onehot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_onehot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_logits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    x = tf.reshape(x, (-1, 28*28))\n",
    "    out = network(x)\n",
    "    y_onehot = tf.one_hot(y, depth=10)\n",
    "    loss = tf.reduce_mean(tf.losses.categorical_crossentropy(y_onehot, out, from_logits=True))\n",
    "    \n",
    "grads = tape.gradient(loss, network.trainable_variables)\n",
    "optimizer.apply_gradients(zip(grads, network.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面一段代码可以简化为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'network' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4600/2923026091.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m network.compile(optimizer=optimizers.Adam(lr=0.01),\n\u001b[0m\u001b[0;32m      2\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCategoricalCrossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfromlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                 metircs=['accuracy'])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'network' is not defined"
     ]
    }
   ],
   "source": [
    "network.compile(optimizer=optimizers.Adam(lr=0.01),\n",
    "                loss=tf.losses.CategoricalCrossentropy(fromlogits=True),\n",
    "                metircs=['accuracy'])\n",
    "\n",
    "network.fit(db, epochs=10)\n",
    "#上面等同于下一句\n",
    "# for epoch in range(epochs):\n",
    "#     for step, (x, y) in enumerate(db):\n",
    "#         # ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化二 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if step % 500 == 0:\n",
    "#     total, total_correct = 0., 0\n",
    "    \n",
    "#     for step, (x, y) in enumerate(ds_val):\n",
    "#         x = tf.reshape(x, (-1, 28*28))\n",
    "#         out = network(x)\n",
    "#         pred = tf.argmax(out, axis=1)\n",
    "#         pred = tf.cast(pred, dtype=tf.int32)\n",
    "#         correct = tf.equal(pred, y)\n",
    "#         total_correct += tf.reduce_sum(tf.cast(correct, dtype=tf.int32)).numpy()\n",
    "#         total += x.shape[0]\n",
    "       \n",
    "#     print(step, 'Evaluate Acc:', total_correct/total)\n",
    "\n",
    "\n",
    "network.compile(optimizer=optimizers.Adam(lr=0.01),\n",
    "                loss=tf.losses.CategoricalCrossentropy(fromlogits=True),\n",
    "                metircs=['accuracy'])\n",
    "\n",
    "# validation_freq=2表示2个epochs做一次验证\n",
    "network.fit(db, epochs=10, validation_data=ds_val, validation_freq=2)\n",
    "\n",
    "#测试\n",
    "network.evaluate(ds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict\n",
    "sample = next(iter(ds_val))\n",
    "x = sample[0]\n",
    "y = sample[1]\n",
    "pred = network.predict(x)\n",
    "y = tf.argmax(y, axis=1)\n",
    "pred = tf.argmax(pre, axis=1)\n",
    "\n",
    "print(pred)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python38]",
   "language": "python",
   "name": "conda-env-python38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "287.812px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
