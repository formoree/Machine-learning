{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据加载\n",
    "+ tf.data.Dataset.from_tensor_slices: 该函数是dataset核心函数之一，给定的张量沿着它们的第一维被切片。此操作保留输入张量的结构，删除每个张量的第一个维，并将其用作数据集维。所有输入张量在其第一维度中必须具有相同的大小\n",
    "+ tf.random.shuffle(a):打乱顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 70s 6us/step\n",
      "11501568/11490434 [==============================] - 70s 6us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mnist数据处理\n",
    "#train:60k//test:10k\n",
    "(x,y),(x_test,y_test) = keras.datasets.mnist.load_data()\n",
    "#因为标签有0-9种情况 进行one_hot编码\n",
    "y_onehot = tf.one_hot(y,depth=10)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #cifar10数据获取\n",
    "# #train 50k//test 10k\n",
    "# (x,y),(x_test,y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from_tensor_slices() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "# next(iter(db)).shape #[28,28]\n",
    "db = tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
    "next(iter(db))[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
    "db = tf.random.shuffle(10000) #db = db.shuffle(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map:数据预处理 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(x,y):\n",
    "    x = tf.cast(x,dtype=tf.float32)/255 #像素点范围为0~255\n",
    "    y = tf.cast(y,dtype=tf.int32)\n",
    "    y = tf.one_hot(y,depth=10)\n",
    "    \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15936/1653421402.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdb2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\4_code\\1_anaconda\\envs\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnp_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m         np_config.enable_numpy_behavior()\"\"\".format(type(self).__name__, name))\n\u001b[1;32m--> 401\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "db2 = db.map(preprocessing)\n",
    "res = next(iter(db))\n",
    "print(res[0].shape,res[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .batch \n",
    "一次得到几张照片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15936/1788105895.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdb3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdb3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'db2' is not defined"
     ]
    }
   ],
   "source": [
    "db3 = db2.batch(32)\n",
    "res = next(iter(db3))\n",
    "print(res[0].shape,res[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_iter = next(iter(db3))\n",
    "while True:\n",
    "    next(db_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#一直循环\n",
    "db4 = db3.repeat()\n",
    "#循环两次\n",
    "db4 = db3.repeat(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = next(iter(db))\n",
    "print(res[0].shape,res[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .batch \n",
    "一次得到几张照片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15088/1788105895.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdb3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdb3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'db2' is not defined"
     ]
    }
   ],
   "source": [
    "db3 = db2.batch(32)\n",
    "res = next(iter(db3))\n",
    "print(res[0].shape,res[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15088/225051282.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdb_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdb3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdb_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'db3' is not defined"
     ]
    }
   ],
   "source": [
    "db_iter = next(iter(db3))\n",
    "while True:\n",
    "    next(db_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15088/298289171.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#一直循环\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdb4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdb3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#循环两次\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdb4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdb3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'db3' is not defined"
     ]
    }
   ],
   "source": [
    "#一直循环\n",
    "db4 = db3.repeat()\n",
    "#循环两次\n",
    "db4 = db3.repeat(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "keyword can't be an expression (Temp/ipykernel_15088/4094015592.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Lenovo\\AppData\\Local\\Temp/ipykernel_15088/4094015592.py\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    y_val = tf.one_hot(y_val.depth=10)\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m keyword can't be an expression\n"
     ]
    }
   ],
   "source": [
    "def preprocessing(x,y):\n",
    "    x = tf.cast(x,dtype=tf.float32)/255\n",
    "    y = tf.cast(y,dtype=tf.int32)\n",
    "    return x,y\n",
    "\n",
    "def mnist_dataset():\n",
    "    (x,y),(x_val,y_val) = keras.datasets.fasion_mnist.load_data() #换数据集了 后面还是X_test\n",
    "    (x,y),(x_val,y_val) = keras.datasets.fasion_mnist.load_data()\n",
    "    y = tf.one_hot(y,depth=10)\n",
    "    y_val = tf.one_hot(y_val.depth=10)\n",
    "    \n",
    "    ds = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "    ds = ds.map(preprocessing)\n",
    "    ds.shuffle(60000).batch(100)\n",
    "    ds_val = tf.data.Dataset.from_tensor_slices((x_val,y_val))\n",
    "    ds_val = ds_val.map(preprocessing)\n",
    "    ds_val.shuffle(60000).batch(100)\n",
    "    return ds,ds_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取数据 并转换类型 \n",
    "+ with tf.GradientTape() as tape:自动微分API，所有操作记录在tape上(**在with下进行数学操作，并存储在tape中**)\n",
    "    + tape.gradients()计算梯度 (得到gradients可能是列表类型的 储存超参数梯度)\n",
    "    + tf.assign_sub(ref, value, use_locking=None, name=None):变量 ref 减去 value值，即 ref = ref - value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x: [60k,28,28], [10,28,28]\n",
    "# y: [60k], [10k]\n",
    "(x, y), (x_test, y_test) = datasets.mnist.load_data()\n",
    "# transform Tensor\n",
    "# x: [0~255] ==》 [0~1.]\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32) / 255.\n",
    "y = tf.convert_to_tensor(y, dtype=tf.int32)\n",
    "x_test = tf.convert_to_tensor(x_test, dtype=tf.float32) / 255.\n",
    "y_test = tf.convert_to_tensor(y_test, dtype=tf.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'batch: (TensorShape([128, 28, 28]), TensorShape([128]))'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch of 128\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x, y)).batch(128)\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(128)\n",
    "train_iter = iter(train_db)\n",
    "sample = next(train_iter)\n",
    "f'batch: {sample[0].shape,sample[1].shape}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在图中创建默认节点 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [b,784] ==> [b,256] ==> [b,128] ==> [b,10]\n",
    "# [dim_in,dim_out],[dim_out]\n",
    "w1 = tf.Variable(tf.random.truncated_normal([784, 256], stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([256]))\n",
    "w2 = tf.Variable(tf.random.truncated_normal([256, 128], stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([128]))\n",
    "w3 = tf.Variable(tf.random.truncated_normal([128, 10], stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#learning rate:0.001\n",
    "lr = 1e-3\n",
    "lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练 梯度下降算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15936/3054041679.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_db\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[1;31m# enumerate(输出行号和内容)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;31m#x:[128,28,28]->[128,28*28]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;31m#y:[28]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_db' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    for step,(x,y) in enumerate(train_db):\n",
    "        # enumerate(输出行号和内容)\n",
    "        #x:[128,28,28]->[128,28*28]\n",
    "        #y:[28]\n",
    "        \n",
    "        x = tf.reshape(x,[-1,28*28])\n",
    "        with tf.GradientTape() as tape:\n",
    "            #TensorFlow 为自动微分提供了 tf.GradientTape API ，根据某个函数的输入变量来计算它的导数\n",
    "            # [b,784]@[784,256]+[256] ==> [b,256] + [256] ==> [b,256] + [b,256]\n",
    "            h1 = x@w1+tf.broadcast_to(b1,[x.shape[0],256])  #(h1 = ax+b)\n",
    "            h1 = tf.nn.relu(h1)\n",
    "            # [b,256] ==> [b,128]\n",
    "            # h2 = x@w2 + b2  # b2 can broadcast automatic\n",
    "            h2 = h1@w2+b2\n",
    "            h2 = tf.nn.relu(h2)\n",
    "            #[b,128]==>[b,10]\n",
    "            out = h2@w3+b3\n",
    "            \n",
    "            #compute losses\n",
    "            y_onehot = tf.one_hot(y,depth=10)\n",
    "            loss = tf.reduce_mean(tf.square(y_onehot-out))\n",
    "            \n",
    "        #compute gradients\n",
    "        grads = tape.gradient(loss,[w1,b1,w2,b2,w3,b3])\n",
    "        # w1 = w1 - lr * w1_grad\n",
    "        # w1 = w1 - lr * grads[0]  # not in situ update\n",
    "        # in situ update\n",
    "        w1.assign_sub(lr * grads[0])\n",
    "        b1.assign_sub(lr * grads[1])\n",
    "        w2.assign_sub(lr * grads[2])\n",
    "        b2.assign_sub(lr * grads[3])\n",
    "        w3.assign_sub(lr * grads[4])\n",
    "        b3.assign_sub(lr * grads[5])\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print(f'epoch:{epoch},step:{step},loss:{float(loss)}')\n",
    "            \n",
    "    total_correct,total_num = 0,0\n",
    "    for step,(x,y) in enumerate(test_db):\n",
    "        x = tf.reshape(x,[-1,28*28])\n",
    "        h1 = tf.nn.relu(x @ w1 + b1)\n",
    "        h2 = tf.nn.relu(h1 @ w2 + b2)\n",
    "        out = h2 @ w3 + b3\n",
    "        \n",
    "        # out: [b,10] ~ R\n",
    "        # prob: [b,10] ~ (0,1)\n",
    "        prob = tf.nn.softmax(out,axis=1)\n",
    "        #[b,10]->[b]\n",
    "        pred = tf.argmax(prob,axis=1)\n",
    "        pred = tf.cast(pred,dtype=tf.int32)\n",
    "        \n",
    "        # y: [b]\n",
    "        # [b], int32\n",
    "        correct = tf.cast(tf.equal(pred, y), dtype=tf.int32)\n",
    "        correct = tf.reduce_sum(correct)\n",
    "\n",
    "        total_correct += int(correct)\n",
    "        total_num += x.shape[0]\n",
    "    acc = total_correct / total_num\n",
    "    print(f'test acc: {acc}')          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简易网络构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全连接层 \n",
    "+ net = tf.keras.layers.Dense()\n",
    "+ net.build(input_shape=()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net的属性为(784, 512),net的bias的属性(512,)\n"
     ]
    }
   ],
   "source": [
    "#自动生成数据\n",
    "x = tf.random.normal([4,784])\n",
    "#构建512神经元的全连接层\n",
    "#[4,784]==>[4,512]\n",
    "net = tf.keras.layers.Dense(512)\n",
    "out = net(x)\n",
    "print(f'net的属性为{net.kernel.shape},net的bias的属性{net.bias.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**如果没有调用Dense函数，我们是无法获取网络的属性，如下代码可见**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Dense' object has no attribute 'kernel'\n"
     ]
    }
   ],
   "source": [
    "# try:\n",
    "#     net = tf.keras.layers.Dense(10)\n",
    "#     net.kernel.shape\n",
    "# except Exception as e:\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_8/kernel:0' shape=(784, 512) dtype=float32, numpy=\n",
       " array([[-0.00380588,  0.05256051,  0.0032768 , ..., -0.0501987 ,\n",
       "         -0.03521321, -0.02314604],\n",
       "        [ 0.05012886, -0.02610995,  0.03664938, ...,  0.05627951,\n",
       "          0.03837027,  0.06231351],\n",
       "        [ 0.02980496, -0.00142232, -0.04249971, ...,  0.02982023,\n",
       "         -0.06580639, -0.02434242],\n",
       "        ...,\n",
       "        [-0.0073201 , -0.0187096 ,  0.01139774, ..., -0.01875522,\n",
       "          0.05221038, -0.0283785 ],\n",
       "        [-0.0045331 , -0.06044547,  0.015029  , ..., -0.04406556,\n",
       "         -0.0294878 , -0.0392484 ],\n",
       "        [-0.0401406 , -0.06779751,  0.00740139, ..., -0.01751142,\n",
       "         -0.04666799,  0.04572296]], dtype=float32)>,\n",
       " <tf.Variable 'dense_8/bias:0' shape=(512,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 10])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#自己设置输入参数类型 通常可一通过输入参数自行设置\n",
    "net = tf.keras.layers.Dense(10)\n",
    "net.build(input_shape=(None,4))\n",
    "net.kernel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'kernel:0' shape=(4, 10) dtype=float32, numpy=\n",
       "array([[ 0.01743668,  0.34845185, -0.33038166,  0.08518714,  0.05131823,\n",
       "         0.51711893,  0.06760114, -0.06391621,  0.41007972,  0.04954326],\n",
       "       [-0.2527593 ,  0.02567559,  0.44043446,  0.60767686,  0.39334548,\n",
       "        -0.13640344, -0.4459053 ,  0.16502273,  0.3048514 ,  0.20030874],\n",
       "       [-0.1994704 ,  0.11549509, -0.07134223, -0.4404649 ,  0.1787523 ,\n",
       "        -0.05017459,  0.06334054, -0.64084655,  0.59652436, -0.5010998 ],\n",
       "       [ 0.17165524, -0.0626235 ,  0.5010228 , -0.18125755, -0.4592874 ,\n",
       "        -0.5692388 , -0.04370642,  0.29609007,  0.2729764 ,  0.10989302]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.build(input_shape=([2,4]))\n",
    "net.kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多层网络\n",
    "+ net = keras.Sequential()\n",
    "+ net.build(input_shape=())\n",
    "+ net.summary():param表示神经元个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             multiple                  8         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             multiple                  6         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             multiple                  6         \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "dense_11/kernel:0 (3, 2)\n",
      "dense_11/bias:0 (2,)\n",
      "dense_12/kernel:0 (2, 2)\n",
      "dense_12/bias:0 (2,)\n",
      "dense_13/kernel:0 (2, 2)\n",
      "dense_13/bias:0 (2,)\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.normal([2,3])\n",
    "\n",
    "#相同操作\n",
    "# model = keras.Sequential()\n",
    "# model.add(keras.layers.Dense(2))\n",
    "# model.add(keras.activations('relu'))\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(2,activation='relu'),\n",
    "    keras.layers.Dense(2,activation='relu'),\n",
    "    keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "model.build(input_shape=([None,3]))\n",
    "model.summary()\n",
    "\n",
    "for p in model.trainable_variables:\n",
    "    print(p.name,p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出方式\n",
    "+ tf.sigmodid()#输出值的和不为1\n",
    "+ tf.nn.softmax() #输出值的和为1\n",
    "+ tf.tanh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 梯度消失或梯度爆炸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 激活函数处理隐藏层--解决梯度消失或梯度爆炸问题：\n",
    "    + ELU>leakyReLu>ReLu>tanh>sigmoid\n",
    "        + 运行性能 leaky ReLu > ELU\n",
    "        + 不想调整参数 α值为:leakyReLu 0.01 ELU 1\n",
    "+ 或者使用梯度裁剪的方式，让梯度不超过阈值：\n",
    "    + clip_by_value()--- apply_gradients()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 动量优化(MomentumOptimizer()):\n",
    "    + 其比梯度下降快，还可以跳过局部最优值\n",
    "    + 它增加了另一个超参数来调整\n",
    "+ 加速梯度(Nesterov)：\n",
    "    + 比常规动量优化快\n",
    "+ AdaGrad:\n",
    "    + 有助于将更新结果直接指向全局最优，也不需要太多地调整学习率超参数\n",
    "    + 停止太快，不可以用其训练深度神经网络\n",
    "+ RMSProp：\n",
    "    + 比前三个好\n",
    "+ Adam优化:\n",
    "    + 更容易使用，超参数调整的少"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学习率调整 \n",
    "+ 预定的分段恒定学习率\n",
    "+ 性能调度\n",
    "+ 指数调度\n",
    "+ 幂调度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正则化避免过拟合\n",
    "+ 早期停止\n",
    "+ L1和L2正则化\n",
    "+ dropout：**被验证非常成功**\n",
    "+ 最大范数正则化：还可以减轻梯度消失/梯度爆炸问题(不进行批量标准化)\n",
    "+ 数据增强:诀窍在于训练逼真的训练实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 误差计算\n",
    "+ tf.losses.MSE(a,b)\n",
    "+ tf.losses.BinaryCrossentropy()([1],[0.1]):当处理二分类问题时使用该交叉熵损失。对于每一个样本的预测值都应该是浮点型的数值(floating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5, 4])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "y = tf.constant([0,1,5,3,2])\n",
    "y = tf.one_hot(y,depth=4)\n",
    "y = tf.cast(y,dtype=tf.float32)\n",
    "\n",
    "out = tf.random.normal([5,4])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1619635, shape=(), dtype=float32, numpy=0.5222829>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss1 = tf.reduce_mean(tf.square(y-out))\n",
    "loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1619655, shape=(), dtype=float32, numpy=1.6566683>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss2 = tf.square(tf.norm(y-out))/( 5 * 4 )\n",
    "loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1619660, shape=(), dtype=float32, numpy=1.6566683>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss3 = tf.reduce_mean(tf.losses.MSE(y,out))\n",
    "loss3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1619694, shape=(), dtype=float32, numpy=2.3025842>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.losses.BinaryCrossentropy()([1],[0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1619719, shape=(), dtype=float32, numpy=2.3025842>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.losses.binary_crossentropy([1],[0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2588 - acc: 0.9252\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1147 - acc: 0.9658\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0782 - acc: 0.9762\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0579 - acc: 0.9824\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0444 - acc: 0.9862\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0778 - acc: 0.9761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0777917131781578, 0.9761000275611877]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 加载mnist数据集\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# print(x_train.shape)\n",
    "# plt.imshow(x_train[0])\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # 归一化\n",
    "y_train_onehot = tf.keras.utils.to_categorical(y_train)  # 将标签转换成独热编码\n",
    "y_test_onehot = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))  # 28*28\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))   # 中间隐藏层激活函数用relu\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))  # 多分类输出一般用softmax分类器\n",
    "\n",
    "#loss函数使用交叉熵\n",
    "# 顺序编码用sparse_categorical_crossentropy\n",
    "# 独热编码用categorical_crossentropy\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train_onehot, epochs=5)\n",
    "\n",
    "model.evaluate(x_test, y_test_onehot)\n",
    "\n",
    "# predict=model.predict(y_test)\n",
    "#\n",
    "# predict.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python38]",
   "language": "python",
   "name": "conda-env-python38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
