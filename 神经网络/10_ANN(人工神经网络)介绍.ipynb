{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据加载\n",
    "+ tf.data.Dataset.from_tensor_slices: 该函数是dataset核心函数之一，给定的张量沿着它们的第一维被切片。此操作保留输入张量的结构，删除每个张量的第一个维，并将其用作数据集维。所有输入张量在其第一维度中必须具有相同的大小\n",
    "+ tf.random.shuffle(a):打乱顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mnist数据处理\n",
    "#train:60k//test:10k\n",
    "(x,y),(x_test,y_test) = keras.datasets.mnist.load_data()\n",
    "#因为标签有0-9种情况 进行one_hot编码\n",
    "y_onehot = tf.one_hot(y,depth=10)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "  2121728/170498071 [..............................] - ETA: 37:20"
     ]
    }
   ],
   "source": [
    "# #cifar10数据获取\n",
    "# #train 50k//test 10k\n",
    "# (x,y),(x_test,y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from_tensor_slices() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "# next(iter(db)).shape #[28,28]\n",
    "db = tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
    "next(iter(db))[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
    "db = tf.random.shuffle(10000) #db = db.shuffle(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map:数据预处理 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(x,y):\n",
    "    x = tf.cast(x,dtype=tf.float32)/255 #像素点范围为0~255\n",
    "    y = tf.cast(y,dtype=tf.int32)\n",
    "    y = tf.one_hot(y,depth=10)\n",
    "    \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "db2 = db.map(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28) ()\n"
     ]
    }
   ],
   "source": [
    "res = next(iter(db))\n",
    "print(res[0].shape,res[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .batch \n",
    "一次得到几张照片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 28, 28) (32, 10)\n"
     ]
    }
   ],
   "source": [
    "db3 = db2.batch(32)\n",
    "res = next(iter(db3))\n",
    "print(res[0].shape,res[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_iter = next(iter(db3))\n",
    "while True:\n",
    "    next(db_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#一直循环\n",
    "db4 = db3.repeat()\n",
    "#循环两次\n",
    "db4 = db3.repeat(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(x,y):\n",
    "    x = tf.cast(x,dtype=tf.float32)/255\n",
    "    y = tf.cast(y,dtype=tf.int32)\n",
    "    return x,y\n",
    "\n",
    "def mnist_dataset():\n",
    "    (x,y),(x_val,y_val) = keras.datasets.fasion_mnist.load_data() #换数据集了 后面还是X_test\n",
    "    y = tf.one_hot(y,depth=10)\n",
    "    y_val = tf.one_hot(y_val.depth=10)\n",
    "    \n",
    "    ds = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "    ds = ds.map(preprocessing)\n",
    "    ds.shuffle(60000).batch(100)\n",
    "    ds_val = tf.data.Dataset.from_tensor_slices((x_val,y_val))\n",
    "    ds_val = ds_val.map(preprocessing)\n",
    "    ds_val.shuffle(60000).batch(100)\n",
    "    return ds,ds_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取数据 并转换类型 \n",
    "+ with tf.GradientTape() as tape:自动微分API，所有操作记录在tape上(**在with下进行数学操作，并存储在tape中**)\n",
    "    + tape.gradients()计算梯度 (得到gradients可能是列表类型的 储存超参数梯度)\n",
    "    + tf.assign_sub(ref, value, use_locking=None, name=None):变量 ref 减去 value值，即 ref = ref - value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x: [60k,28,28], [10,28,28]\n",
    "# y: [60k], [10k]\n",
    "(x, y), (x_test, y_test) = datasets.mnist.load_data()\n",
    "# transform Tensor\n",
    "# x: [0~255] ==》 [0~1.]\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32) / 255.\n",
    "y = tf.convert_to_tensor(y, dtype=tf.int32)\n",
    "x_test = tf.convert_to_tensor(x_test, dtype=tf.float32) / 255.\n",
    "y_test = tf.convert_to_tensor(y_test, dtype=tf.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'batch: (TensorShape([128, 28, 28]), TensorShape([128]))'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch of 128\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x, y)).batch(128)\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(128)\n",
    "train_iter = iter(train_db)\n",
    "sample = next(train_iter)\n",
    "f'batch: {sample[0].shape,sample[1].shape}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在图中创建默认节点 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [b,784] ==> [b,256] ==> [b,128] ==> [b,10]\n",
    "# [dim_in,dim_out],[dim_out]\n",
    "w1 = tf.Variable(tf.random.truncated_normal([784, 256], stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([256]))\n",
    "w2 = tf.Variable(tf.random.truncated_normal([256, 128], stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([128]))\n",
    "w3 = tf.Variable(tf.random.truncated_normal([128, 10], stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#learning rate:0.001\n",
    "lr = 1e-3\n",
    "lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练 梯度下降算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0,step:0,loss:0.06983967870473862\n",
      "epoch:0,step:100,loss:0.08042538911104202\n",
      "epoch:0,step:200,loss:0.08418109267950058\n",
      "epoch:0,step:300,loss:0.07312164455652237\n",
      "epoch:0,step:400,loss:0.07665024697780609\n",
      "test acc: 0.5933\n",
      "epoch:1,step:0,loss:0.06795628368854523\n",
      "epoch:1,step:100,loss:0.07856154441833496\n",
      "epoch:1,step:200,loss:0.08198012411594391\n",
      "epoch:1,step:300,loss:0.07137195765972137\n",
      "epoch:1,step:400,loss:0.07486895471811295\n",
      "test acc: 0.6082\n",
      "epoch:2,step:0,loss:0.06624337285757065\n",
      "epoch:2,step:100,loss:0.07687604427337646\n",
      "epoch:2,step:200,loss:0.079964280128479\n",
      "epoch:2,step:300,loss:0.06978429853916168\n",
      "epoch:2,step:400,loss:0.07327441871166229\n",
      "test acc: 0.6208\n",
      "epoch:3,step:0,loss:0.06469006836414337\n",
      "epoch:3,step:100,loss:0.075334332883358\n",
      "epoch:3,step:200,loss:0.07811331748962402\n",
      "epoch:3,step:300,loss:0.06834663450717926\n",
      "epoch:3,step:400,loss:0.07182338088750839\n",
      "test acc: 0.6339\n",
      "epoch:4,step:0,loss:0.06327065080404282\n",
      "epoch:4,step:100,loss:0.07393507659435272\n",
      "epoch:4,step:200,loss:0.07640708237886429\n",
      "epoch:4,step:300,loss:0.06701725721359253\n",
      "epoch:4,step:400,loss:0.07049083709716797\n",
      "test acc: 0.6445\n",
      "epoch:5,step:0,loss:0.06195317581295967\n",
      "epoch:5,step:100,loss:0.0726439580321312\n",
      "epoch:5,step:200,loss:0.07483562082052231\n",
      "epoch:5,step:300,loss:0.06578902900218964\n",
      "epoch:5,step:400,loss:0.06927604973316193\n",
      "test acc: 0.6514\n",
      "epoch:6,step:0,loss:0.0607319101691246\n",
      "epoch:6,step:100,loss:0.07145099341869354\n",
      "epoch:6,step:200,loss:0.0733659416437149\n",
      "epoch:6,step:300,loss:0.06465061008930206\n",
      "epoch:6,step:400,loss:0.068151094019413\n",
      "test acc: 0.6614\n",
      "epoch:7,step:0,loss:0.059601008892059326\n",
      "epoch:7,step:100,loss:0.07035023719072342\n",
      "epoch:7,step:200,loss:0.07198639214038849\n",
      "epoch:7,step:300,loss:0.06360237300395966\n",
      "epoch:7,step:400,loss:0.06710396707057953\n",
      "test acc: 0.6701\n",
      "epoch:8,step:0,loss:0.05854414030909538\n",
      "epoch:8,step:100,loss:0.06931933015584946\n",
      "epoch:8,step:200,loss:0.07069273293018341\n",
      "epoch:8,step:300,loss:0.06262834370136261\n",
      "epoch:8,step:400,loss:0.06611268222332001\n",
      "test acc: 0.677\n",
      "epoch:9,step:0,loss:0.05755817890167236\n",
      "epoch:9,step:100,loss:0.06834959983825684\n",
      "epoch:9,step:200,loss:0.06948374956846237\n",
      "epoch:9,step:300,loss:0.06171829625964165\n",
      "epoch:9,step:400,loss:0.06517059355974197\n",
      "test acc: 0.6836\n",
      "epoch:10,step:0,loss:0.056634437292814255\n",
      "epoch:10,step:100,loss:0.06743625551462173\n",
      "epoch:10,step:200,loss:0.06834723800420761\n",
      "epoch:10,step:300,loss:0.060860831290483475\n",
      "epoch:10,step:400,loss:0.06428928673267365\n",
      "test acc: 0.6897\n",
      "epoch:11,step:0,loss:0.055761437863111496\n",
      "epoch:11,step:100,loss:0.06657402217388153\n",
      "epoch:11,step:200,loss:0.06727747619152069\n",
      "epoch:11,step:300,loss:0.06004451587796211\n",
      "epoch:11,step:400,loss:0.06345661729574203\n",
      "test acc: 0.6955\n",
      "epoch:12,step:0,loss:0.05494292825460434\n",
      "epoch:12,step:100,loss:0.06575615704059601\n",
      "epoch:12,step:200,loss:0.0662795677781105\n",
      "epoch:12,step:300,loss:0.05927581340074539\n",
      "epoch:12,step:400,loss:0.06267468631267548\n",
      "test acc: 0.701\n",
      "epoch:13,step:0,loss:0.05417673662304878\n",
      "epoch:13,step:100,loss:0.06498029083013535\n",
      "epoch:13,step:200,loss:0.06533665955066681\n",
      "epoch:13,step:300,loss:0.05854877084493637\n",
      "epoch:13,step:400,loss:0.06193960830569267\n",
      "test acc: 0.7065\n",
      "epoch:14,step:0,loss:0.05345265194773674\n",
      "epoch:14,step:100,loss:0.0642397403717041\n",
      "epoch:14,step:200,loss:0.06444613635540009\n",
      "epoch:14,step:300,loss:0.05786644294857979\n",
      "epoch:14,step:400,loss:0.061238843947649\n",
      "test acc: 0.7125\n",
      "epoch:15,step:0,loss:0.05276768282055855\n",
      "epoch:15,step:100,loss:0.06353703886270523\n",
      "epoch:15,step:200,loss:0.06360308080911636\n",
      "epoch:15,step:300,loss:0.057222943753004074\n",
      "epoch:15,step:400,loss:0.06056768819689751\n",
      "test acc: 0.7179\n",
      "epoch:16,step:0,loss:0.05212128907442093\n",
      "epoch:16,step:100,loss:0.06286757439374924\n",
      "epoch:16,step:200,loss:0.06279848515987396\n",
      "epoch:16,step:300,loss:0.056602466851472855\n",
      "epoch:16,step:400,loss:0.05993847921490669\n",
      "test acc: 0.7225\n",
      "epoch:17,step:0,loss:0.051504217088222504\n",
      "epoch:17,step:100,loss:0.06222112849354744\n",
      "epoch:17,step:200,loss:0.06203053519129753\n",
      "epoch:17,step:300,loss:0.05601339414715767\n",
      "epoch:17,step:400,loss:0.05934600159525871\n",
      "test acc: 0.7265\n",
      "epoch:18,step:0,loss:0.05091426521539688\n",
      "epoch:18,step:100,loss:0.06160839647054672\n",
      "epoch:18,step:200,loss:0.061302751302719116\n",
      "epoch:18,step:300,loss:0.05545879527926445\n",
      "epoch:18,step:400,loss:0.05877412110567093\n",
      "test acc: 0.7306\n",
      "epoch:19,step:0,loss:0.050354134291410446\n",
      "epoch:19,step:100,loss:0.06102956458926201\n",
      "epoch:19,step:200,loss:0.060610078275203705\n",
      "epoch:19,step:300,loss:0.054931651800870895\n",
      "epoch:19,step:400,loss:0.05822188779711723\n",
      "test acc: 0.7349\n",
      "epoch:20,step:0,loss:0.04981867969036102\n",
      "epoch:20,step:100,loss:0.060471922159194946\n",
      "epoch:20,step:200,loss:0.05994098633527756\n",
      "epoch:20,step:300,loss:0.05442362278699875\n",
      "epoch:20,step:400,loss:0.05769370123744011\n",
      "test acc: 0.7381\n",
      "epoch:21,step:0,loss:0.049311570823192596\n",
      "epoch:21,step:100,loss:0.059938304126262665\n",
      "epoch:21,step:200,loss:0.059297412633895874\n",
      "epoch:21,step:300,loss:0.053933657705783844\n",
      "epoch:21,step:400,loss:0.05718641355633736\n",
      "test acc: 0.7417\n",
      "epoch:22,step:0,loss:0.04882759600877762\n",
      "epoch:22,step:100,loss:0.05942981317639351\n",
      "epoch:22,step:200,loss:0.05867312103509903\n",
      "epoch:22,step:300,loss:0.05346198007464409\n",
      "epoch:22,step:400,loss:0.05670050531625748\n",
      "test acc: 0.746\n",
      "epoch:23,step:0,loss:0.04836349934339523\n",
      "epoch:23,step:100,loss:0.058940816670656204\n",
      "epoch:23,step:200,loss:0.058071088045835495\n",
      "epoch:23,step:300,loss:0.053005289286375046\n",
      "epoch:23,step:400,loss:0.05623156949877739\n",
      "test acc: 0.7496\n",
      "epoch:24,step:0,loss:0.04791605845093727\n",
      "epoch:24,step:100,loss:0.05846930667757988\n",
      "epoch:24,step:200,loss:0.05749398469924927\n",
      "epoch:24,step:300,loss:0.05256624147295952\n",
      "epoch:24,step:400,loss:0.055780697613954544\n",
      "test acc: 0.7543\n",
      "epoch:25,step:0,loss:0.047485314309597015\n",
      "epoch:25,step:100,loss:0.0580127127468586\n",
      "epoch:25,step:200,loss:0.05693751573562622\n",
      "epoch:25,step:300,loss:0.05214418098330498\n",
      "epoch:25,step:400,loss:0.055344872176647186\n",
      "test acc: 0.7589\n",
      "epoch:26,step:0,loss:0.04707431048154831\n",
      "epoch:26,step:100,loss:0.0575709342956543\n",
      "epoch:26,step:200,loss:0.056399811059236526\n",
      "epoch:26,step:300,loss:0.05173908919095993\n",
      "epoch:26,step:400,loss:0.054922353476285934\n",
      "test acc: 0.7615\n",
      "epoch:27,step:0,loss:0.046682022511959076\n",
      "epoch:27,step:100,loss:0.057139553129673004\n",
      "epoch:27,step:200,loss:0.05588294193148613\n",
      "epoch:27,step:300,loss:0.05134638398885727\n",
      "epoch:27,step:400,loss:0.05451049655675888\n",
      "test acc: 0.7647\n",
      "epoch:28,step:0,loss:0.04630506411194801\n",
      "epoch:28,step:100,loss:0.05672506242990494\n",
      "epoch:28,step:200,loss:0.055389653891325\n",
      "epoch:28,step:300,loss:0.050965677946805954\n",
      "epoch:28,step:400,loss:0.054108332842588425\n",
      "test acc: 0.7674\n",
      "epoch:29,step:0,loss:0.04594001919031143\n",
      "epoch:29,step:100,loss:0.05632805824279785\n",
      "epoch:29,step:200,loss:0.054914940148591995\n",
      "epoch:29,step:300,loss:0.050597477704286575\n",
      "epoch:29,step:400,loss:0.053718339651823044\n",
      "test acc: 0.7696\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    for step,(x,y) in enumerate(train_db):\n",
    "        # enumerate(输出行号和内容)\n",
    "        #x:[128,28,28]->[128,28*28]\n",
    "        #y:[28]\n",
    "        \n",
    "        x = tf.reshape(x,[-1,28*28])\n",
    "        with tf.GradientTape() as tape:\n",
    "            #TensorFlow 为自动微分提供了 tf.GradientTape API ，根据某个函数的输入变量来计算它的导数\n",
    "            # [b,784]@[784,256]+[256] ==> [b,256] + [256] ==> [b,256] + [b,256]\n",
    "            h1 = x@w1+tf.broadcast_to(b1,[x.shape[0],256])  #(h1 = ax+b)\n",
    "            h1 = tf.nn.relu(h1)\n",
    "            # [b,256] ==> [b,128]\n",
    "            # h2 = x@w2 + b2  # b2 can broadcast automatic\n",
    "            h2 = h1@w2+b2\n",
    "            h2 = tf.nn.relu(h2)\n",
    "            #[b,128]==>[b,10]\n",
    "            out = h2@w3+b3\n",
    "            \n",
    "            #compute losses\n",
    "            y_onehot = tf.one_hot(y,depth=10)\n",
    "            loss = tf.reduce_mean(tf.square(y_onehot-out))\n",
    "            \n",
    "        #compute gradients\n",
    "        grads = tape.gradient(loss,[w1,b1,w2,b2,w3,b3])\n",
    "        # w1 = w1 - lr * w1_grad\n",
    "        # w1 = w1 - lr * grads[0]  # not in situ update\n",
    "        # in situ update\n",
    "        w1.assign_sub(lr * grads[0])\n",
    "        b1.assign_sub(lr * grads[1])\n",
    "        w2.assign_sub(lr * grads[2])\n",
    "        b2.assign_sub(lr * grads[3])\n",
    "        w3.assign_sub(lr * grads[4])\n",
    "        b3.assign_sub(lr * grads[5])\n",
    "        \n",
    "        if step%100 == 0:\n",
    "            print(f'epoch:{epoch},step:{step},loss:{float(loss)}')\n",
    "            \n",
    "    total_correct,total_num = 0,0\n",
    "    for step,(x,y) in enumerate(test_db):\n",
    "        x = tf.reshape(x,[-1,28*28])\n",
    "        h1 = tf.nn.relu(x @ w1 + b1)\n",
    "        h2 = tf.nn.relu(h1 @ w2 + b2)\n",
    "        out = h2 @ w3 + b3\n",
    "        \n",
    "        # out: [b,10] ~ R\n",
    "        # prob: [b,10] ~ (0,1)\n",
    "        prob = tf.nn.softmax(out,axis=1)\n",
    "        #[b,10]->[b]\n",
    "        pred = tf.argmax(prob,axis=1)\n",
    "        pred = tf.cast(pred,dtype=tf.int32)\n",
    "        \n",
    "        # y: [b]\n",
    "        # [b], int32\n",
    "        correct = tf.cast(tf.equal(pred, y), dtype=tf.int32)\n",
    "        correct = tf.reduce_sum(correct)\n",
    "\n",
    "        total_correct += int(correct)\n",
    "        total_num += x.shape[0]\n",
    "    acc = total_correct / total_num\n",
    "    print(f'test acc: {acc}')          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简易网络构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全连接层 \n",
    "+ net = tf.keras.layers.Dense()\n",
    "+ net.build(input_shape=()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net的属性为(784, 512),net的bias的属性(512,)\n"
     ]
    }
   ],
   "source": [
    "#自动生成数据\n",
    "x = tf.random.normal([4,784])\n",
    "#构建512神经元的全连接层\n",
    "#[4,784]==>[4,512]\n",
    "net = tf.keras.layers.Dense(512)\n",
    "out = net(x)\n",
    "print(f'net的属性为{net.kernel.shape},net的bias的属性{net.bias.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**如果没有调用Dense函数，我们是无法获取网络的属性，如下代码可见**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Dense' object has no attribute 'kernel'\n"
     ]
    }
   ],
   "source": [
    "# try:\n",
    "#     net = tf.keras.layers.Dense(10)\n",
    "#     net.kernel.shape\n",
    "# except Exception as e:\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_8/kernel:0' shape=(784, 512) dtype=float32, numpy=\n",
       " array([[-0.00380588,  0.05256051,  0.0032768 , ..., -0.0501987 ,\n",
       "         -0.03521321, -0.02314604],\n",
       "        [ 0.05012886, -0.02610995,  0.03664938, ...,  0.05627951,\n",
       "          0.03837027,  0.06231351],\n",
       "        [ 0.02980496, -0.00142232, -0.04249971, ...,  0.02982023,\n",
       "         -0.06580639, -0.02434242],\n",
       "        ...,\n",
       "        [-0.0073201 , -0.0187096 ,  0.01139774, ..., -0.01875522,\n",
       "          0.05221038, -0.0283785 ],\n",
       "        [-0.0045331 , -0.06044547,  0.015029  , ..., -0.04406556,\n",
       "         -0.0294878 , -0.0392484 ],\n",
       "        [-0.0401406 , -0.06779751,  0.00740139, ..., -0.01751142,\n",
       "         -0.04666799,  0.04572296]], dtype=float32)>,\n",
       " <tf.Variable 'dense_8/bias:0' shape=(512,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 10])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#自己设置输入参数类型 通常可一通过输入参数自行设置\n",
    "net = tf.keras.layers.Dense(10)\n",
    "net.build(input_shape=(None,4))\n",
    "net.kernel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'kernel:0' shape=(4, 10) dtype=float32, numpy=\n",
       "array([[ 0.01743668,  0.34845185, -0.33038166,  0.08518714,  0.05131823,\n",
       "         0.51711893,  0.06760114, -0.06391621,  0.41007972,  0.04954326],\n",
       "       [-0.2527593 ,  0.02567559,  0.44043446,  0.60767686,  0.39334548,\n",
       "        -0.13640344, -0.4459053 ,  0.16502273,  0.3048514 ,  0.20030874],\n",
       "       [-0.1994704 ,  0.11549509, -0.07134223, -0.4404649 ,  0.1787523 ,\n",
       "        -0.05017459,  0.06334054, -0.64084655,  0.59652436, -0.5010998 ],\n",
       "       [ 0.17165524, -0.0626235 ,  0.5010228 , -0.18125755, -0.4592874 ,\n",
       "        -0.5692388 , -0.04370642,  0.29609007,  0.2729764 ,  0.10989302]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.build(input_shape=([2,4]))\n",
    "net.kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多层网络\n",
    "+ net = keras.Sequential()\n",
    "+ net.build(input_shape=())\n",
    "+ net.summary():param表示神经元个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             multiple                  8         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             multiple                  6         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             multiple                  6         \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "dense_11/kernel:0 (3, 2)\n",
      "dense_11/bias:0 (2,)\n",
      "dense_12/kernel:0 (2, 2)\n",
      "dense_12/bias:0 (2,)\n",
      "dense_13/kernel:0 (2, 2)\n",
      "dense_13/bias:0 (2,)\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.normal([2,3])\n",
    "\n",
    "#相同操作\n",
    "# model = keras.Sequential()\n",
    "# model.add(keras.layers.Dense(2))\n",
    "# model.add(keras.activations('relu'))\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(2,activation='relu'),\n",
    "    keras.layers.Dense(2,activation='relu'),\n",
    "    keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "model.build(input_shape=([None,3]))\n",
    "model.summary()\n",
    "\n",
    "for p in model.trainable_variables:\n",
    "    print(p.name,p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出方式\n",
    "+ tf.sigmodid()#输出值的和不为1\n",
    "+ tf.nn.softmax() #输出值的和为1\n",
    "+ tf.tanh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 误差计算\n",
    "+ tf.losses.MSE(a,b)\n",
    "+ tf.losses.BinaryCrossentropy()([1],[0.1]):当处理二分类问题时使用该交叉熵损失。对于每一个样本的预测值都应该是浮点型的数值(floating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5, 4])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "y = tf.constant([0,1,5,3,2])\n",
    "y = tf.one_hot(y,depth=4)\n",
    "y = tf.cast(y,dtype=tf.float32)\n",
    "\n",
    "out = tf.random.normal([5,4])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1619635, shape=(), dtype=float32, numpy=0.5222829>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss1 = tf.reduce_mean(tf.square(y-out))\n",
    "loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1619655, shape=(), dtype=float32, numpy=1.6566683>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss2 = tf.square(tf.norm(y-out))/( 5 * 4 )\n",
    "loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1619660, shape=(), dtype=float32, numpy=1.6566683>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss3 = tf.reduce_mean(tf.losses.MSE(y,out))\n",
    "loss3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1619694, shape=(), dtype=float32, numpy=2.3025842>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.losses.BinaryCrossentropy()([1],[0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1619719, shape=(), dtype=float32, numpy=2.3025842>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.losses.binary_crossentropy([1],[0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Learn]",
   "language": "python",
   "name": "conda-env-Learn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
